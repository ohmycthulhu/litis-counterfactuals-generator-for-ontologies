## Explainable AI (XAI) A systematic meta-survey of current challenges and future opportunities
Source: [[Explainable AI (XAI) A systematic meta-survey of current challenges and future opportunities.pdf]]

It researches the current state of XAI, provides the potential research directions. 

The valuable points from the survey:
- the challenges in the existing XAI models/methods
- the advantages of analyzing models rather than data
- the importance to know when it is reasonable to incur additional costs for explanations.

It contains more than 150 articles in the references, it may be useful to check them.

**The important survey, should be used to extract knowledge and get more articles, in case we need it.**

****

## Explainable Artificial Intelligence (XAI) Concepts, taxonomies, opportunities and challenges toward responsible AI
Source: [[Explainable Artificial Intelligence (XAI) Concepts, taxonomies, opportunities and challenges toward responsible AI.pdf]]

Analyses the terminology and techniques used in **machine learning models**. It also defines the term "Responsible AI".

**The survery aims at mostly on the deep models, so there is no much to do there.**

****

## Explainable Machine Learning with Prior Knowledge
Source: [[Deep models/EXPLAINABLE MACHINE LEARNING WITH PRIOR KNOWLEDGE.pdf]]

*What is prior knowledge?*
Prior knowledge represent the context information, often indicating the importance of features and their relations.

*Is prior knowledge applicable to ontology-based models?*
It seems like the prior knowledge is represented by ontology's T-Box. The addition of other context information may be redundant (as we already have it).


****


## Argumentation and explainable artificial intelligence
Source: [[Argumentation and explainable artificial intelligence.pdf]]

The work is focused on combining Argumentation with Explainable AI in the context of machine learning models.

**The work is irrelevant**

****

## Explainable framework for meta-learning in automatic classification algorithm selection
Source: [[Deep models/Explainable framework for meta-learning in automatic classification algorithm selection.pdf]]

Question: why the framework is explainable and how the achieved it?

> A causal relationship between the features shows that changes in certain aspects induce changes in other features and that changes in the outcomes occur from the combined effect of both features

The explainable part is generation counterfactuals based on greedy algorithms with prioritizing certain features.

**The work is irrelevant.**

****

## Knowledge graphs as tools for explainable machine learning
Source: [[Knowledge graphs as tools for explainable machine learning.pdf]]

The work is aimed at analysing how knowledge graphs can be used to build explainable machine learning models.

**The work is irrelevant to the topic.**

****

## Completing and Debugging Ontologies State of the Art and Challenges
Source: [[Completing and Debugging Ontologies State of the Art and Challenges.pdf]]

The page is focused on repairing the broken ontologies. The work can be quite useful, especially for: [[Approaches/WhiteBox]]

**Useful survey for exploring how to fix broken ontologies and work with ontologies.**
**The one way of further research is to find ways to detect errors.**

****

## A Survey of Contrastive and Counterfactual
Explanation Generation Methods for Explainable Artificial Intelligence
Source: [[A Survey of Contrastive and Counterfactual Explanation Generation Methods for Explainable Artificial Intelligence.pdf]]

The survey contains an overview of existing approaches to generating counterfactuals, which may be useful.****

****

## The Role of Human Knowledge in Explainable AI
Source: [[The Role of Human Knowledge in Explainable AI.pdf]]

The work analyses and discusses the usage of human knowledge and "human reasonale" to enhance the explainability of the machine learning models.

**The survey is unrelated and won't be used.**

****

## Explainable AI current status and future directions
Source: [[Explainable AI current status and future directions.pdf]]

Its introduction contains useful links. It can be used for describing different approaches and existing techniques.
Nevertheless, the approach and analysis itself are more about multimedia and specifically ML models.

**The work may be used for writing introduction and field overview.**

****

## Automated and Explainable Ontology Extension Based on Deep Learning
Source: [[Deep models/Automated and Explainable Ontology Extension Based on Deep Learning.pdf]]

The paper contains automatic extension of the existing ontologies. The algorithm is applied onto the ontology in chemical domain. 

**We can try checking implementation for [[WhiteBox]]**

****

## Semantic Web Technologies for Explainable Machine Learning Models
Source: [[Deep models/Semantic Web Technologies for Explainable Machine Learning Models.pdf]]

The article explores the existing methods of incorporating Semantic Web with ML models in order to increase the latter's explainability.

*What is "knowledge matching"?*
> ... the matching of ML data with knowledge base entities ... knowledge matching

The existing articles provide manual way of knowledge matching. 

**The work is irrelevant due to absense of topics that we are interested in.**

****

## Counterfactuals and causability in explainable artificial intelligence Theory, algorithms, and applications
Source: [[Counterfactuals and causability in explainable artificial intelligence Theory, algorithms, and applications.pdf]]

The survey aims at exploring existing algorithms and overview of use causability to make distinction between explanations. 

> We extended the current literature by proposing a new taxonomy for model-agnostic counterfactuals based on six approaches: instance-centric, constraint-centric, genetic-centric, regression-centric, game theory-centric, case-based reasoning centric, and probabilistic-centric

**The work is irrelevant.**

****

## Knowledge-graph-based explainable AI
Source: [[Knowledge-graph-based explainable AI.pdf]]

The survey focuses on the usage of knowledge-graphs (KGs) in explainable AI. It ostly observes KGs as a tool to find and define relations between features, utilize reasoning for explaining ML models predictions, and other approaches that do not use KG directly for predictions.

**The work is irrelevant yet still interesting.**